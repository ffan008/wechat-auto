"""
Analytics Agent - æ•°æ®åˆ†æAgent
è´Ÿè´£æ•°æ®é‡‡é›†ã€æŒ‡æ ‡è®¡ç®—ã€æ´å¯Ÿç”Ÿæˆ
"""
from typing import Dict, Any, List
from datetime import datetime, timedelta
from src.agents.base_agent import BaseAgent
from src.graph.state import AgentState
from src.database.crud import AnalyticsCRUD, ContentCRUD
from src.database.session import db_manager
from src.wechat.api_client import wechat_api_client


class AnalyticsAgent(BaseAgent):
    """åˆ†æAgent - è´Ÿè´£æ•°æ®åˆ†æ"""

    def __init__(self):
        super().__init__("analytics_agent")

    async def invoke(self, state: AgentState) -> AgentState:
        """
        æ‰§è¡Œåˆ†æAgenté€»è¾‘

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        self.log_invocation(state)

        user_id = state.get("user_id")
        message = state.get("message", "")

        # 1. è§£æåˆ†æè¯·æ±‚
        analysis_type = await self._parse_analysis_request(message)

        # 2. é‡‡é›†æ•°æ®
        data = await self._collect_data(analysis_type)

        # 3. è®¡ç®—æŒ‡æ ‡
        metrics = await self._calculate_metrics(data)

        # 4. ç”Ÿæˆæ´å¯Ÿ
        insights = await self._generate_insights(metrics)

        # 5. ç”ŸæˆæŠ¥å‘Š
        report = await self._generate_report(metrics, insights)

        # 6. ä¿å­˜å¿«ç…§
        await self._save_snapshot(metrics)

        # 7. æ„å»ºå“åº”
        response = f"""æ•°æ®åˆ†ææŠ¥å‘Š ğŸ“Š

{report}

å…³é”®æ´å¯Ÿï¼š
{chr(10).join([f'â€¢ {insight}' for insight in insights[:5]])}

è¯¦ç»†æ•°æ®å·²ä¿å­˜ã€‚"""

        state = self.update_state(
            state,
            analytics_data=metrics,
            insights=insights,
            response_message=response,
            metadata={
                "analysis_type": analysis_type,
                "data_points": len(data),
                "timestamp": datetime.now().isoformat()
            }
        )

        state["agent_chain"] = state.get("agent_chain", []) + [self.name]

        print(f"[{self.name}] Analytics completed: {analysis_type}")
        return state

    async def _parse_analysis_request(self, message: str) -> str:
        """
        è§£æåˆ†æè¯·æ±‚ç±»å‹

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            åˆ†æç±»å‹
        """
        message_lower = message.lower()

        if any(word in message_lower for word in ["ç”¨æˆ·", "ç²‰ä¸", "å¢é•¿"]):
            return "user_growth"
        elif any(word in message_lower for word in ["æ–‡ç« ", "å†…å®¹", "é˜…è¯»"]):
            return "content_performance"
        elif any(word in message_lower for word in ["äº’åŠ¨", "è¯„è®º", "ç‚¹èµ"]):
            return "engagement"
        elif any(word in message_lower for word in ["å…¨", "å…¨éƒ¨", "æ•´ä½“"]):
            return "overview"
        else:
            return "overview"

    async def _collect_data(self, analysis_type: str) -> List[Dict[str, Any]]:
        """
        é‡‡é›†æ•°æ®

        Args:
            analysis_type: åˆ†æç±»å‹

        Returns:
            æ•°æ®åˆ—è¡¨
        """
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)

        with db_manager.get_session() as db:
            if analysis_type == "content_performance":
                # è·å–å†…å®¹æ•°æ®
                contents = ContentCRUD.get_top_content(db, days=7, limit=50)
                return [
                    {
                        "id": c.id,
                        "title": c.title,
                        "views": c.views,
                        "likes": c.likes,
                        "shares": c.shares,
                        "publish_time": c.publish_time.isoformat() if c.publish_time else None
                    }
                    for c in contents
                ]

            elif analysis_type == "user_growth":
                # è·å–ç”¨æˆ·å¿«ç…§
                snapshots = db.query(AnalyticsSnapshot).filter(
                    AnalyticsSnapshot.snapshot_type == "daily"
                ).order_by(AnalyticsSnapshot.snapshot_date.desc()).limit(7).all()

                return [
                    {
                        "date": s.snapshot_date.isoformat(),
                        "total_followers": s.total_followers,
                        "new_followers": s.new_followers,
                        "lost_followers": s.lost_followers
                    }
                    for s in snapshots
                ]

            else:
                # æ¦‚è§ˆæ•°æ®
                snapshot = AnalyticsCRUD.get_latest_snapshot(db, "daily")
                if snapshot:
                    return [{
                        "total_followers": snapshot.total_followers,
                        "total_articles": snapshot.total_articles,
                        "total_views": snapshot.total_views,
                        "total_interactions": snapshot.total_interactions
                    }]
                return []

    async def _calculate_metrics(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è®¡ç®—æŒ‡æ ‡

        Args:
            data: åŸå§‹æ•°æ®

        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        if not data:
            return {}

        metrics = {
            "data_count": len(data),
            "timestamp": datetime.now().isoformat()
        }

        # æ ¹æ®æ•°æ®ç±»å‹è®¡ç®—ä¸åŒæŒ‡æ ‡
        if "views" in data[0]:  # å†…å®¹æ•°æ®
            total_views = sum(item.get("views", 0) for item in data)
            total_likes = sum(item.get("likes", 0) for item in data)
            total_shares = sum(item.get("shares", 0) for item in data)

            metrics.update({
                "total_views": total_views,
                "avg_views": total_views / len(data),
                "total_likes": total_likes,
                "total_shares": total_shares,
                "engagement_rate": (total_likes + total_shares) / total_views if total_views > 0 else 0
            })

        elif "new_followers" in data[0]:  # ç”¨æˆ·æ•°æ®
            total_new = sum(item.get("new_followers", 0) for item in data)
            total_lost = sum(item.get("lost_followers", 0) for item in data)

            metrics.update({
                "total_new_followers": total_new,
                "total_lost_followers": total_lost,
                "net_growth": total_new - total_lost,
                "avg_daily_growth": total_new / len(data)
            })

        return metrics

    async def _generate_insights(self, metrics: Dict[str, Any]) -> List[str]:
        """
        ç”Ÿæˆæ´å¯Ÿ

        Args:
            metrics: æŒ‡æ ‡æ•°æ®

        Returns:
            æ´å¯Ÿåˆ—è¡¨
        """
        prompt = f"""ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ•°æ®ï¼Œç”Ÿæˆ5-8æ¡å…³é”®æ´å¯Ÿã€‚

æ•°æ®ï¼š
{metrics}

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{"insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", ...]}}

è¦æ±‚ï¼š
1. æ´å¯Ÿè¦æ·±åˆ»ï¼Œç›´å‡»è¦ç‚¹
2. åŸºäºæ•°æ®ï¼Œæœ‰ç†æœ‰æ®
3. æä¾›å¯æ‰§è¡Œçš„å»ºè®®"""

        try:
            response = self.call_claude(prompt, max_tokens=1000)
            result = eval(response)  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç”¨json.loads
            return result.get("insights", [])

        except Exception as e:
            print(f"[{self.name}] ç”Ÿæˆæ´å¯Ÿå¤±è´¥: {e}")

            # é™çº§ï¼šç”Ÿæˆç®€å•æ´å¯Ÿ
            insights = []
            if "total_views" in metrics:
                insights.append(f"æ€»é˜…è¯»é‡è¾¾åˆ° {metrics['total_views']} æ¬¡")
            if "net_growth" in metrics:
                insights.append(f"ç²‰ä¸å‡€å¢é•¿ {metrics['net_growth']} äºº")

            return insights

    async def _generate_report(self, metrics: Dict[str, Any], insights: List[str]) -> str:
        """
        ç”ŸæˆæŠ¥å‘Š

        Args:
            metrics: æŒ‡æ ‡
            insights: æ´å¯Ÿ

        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = ["æ ¸å¿ƒæŒ‡æ ‡ï¼š"]

        for key, value in metrics.items():
            if key not in ["data_count", "timestamp"]:
                # æ ¼å¼åŒ–key
                formatted_key = key.replace("_", " ").title()
                report_lines.append(f"- {formatted_key}: {value}")

        return "\n".join(report_lines)

    async def _save_snapshot(self, metrics: Dict[str, Any]):
        """
        ä¿å­˜æ•°æ®å¿«ç…§

        Args:
            metrics: æŒ‡æ ‡æ•°æ®
        """
        with db_manager.get_session() as db:
            AnalyticsCRUD.create_snapshot(
                db,
                snapshot_date=datetime.now(),
                snapshot_type="daily",
                **metrics
            )
